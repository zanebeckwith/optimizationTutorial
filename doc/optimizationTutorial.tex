% Tutorial on mathematical optimization, 
% given to students in the UNC-CH CAP-REU program
% during the summer of 2013.
%
% Designed to be used after a ~1.5hr intro to
% random numbers and Monte Carlo
%
% Author: Zane Beckwith

\documentclass{article}
\usepackage[colorlinks=true]{hyperref}

\begin{document}

\title{Brief Introduction to Mathematical Optimization}
\author{Zane Beckwith \\
UNC-CH CAP-REU Program}
\date{Summer 2013}
\maketitle

These notes are a very brief introduction to the very not-brief field of 
mathematical optimization. I want to stress that this tutorial does not
pretend to be complete, and its author does not pretend to be an expert
on the field. Because I'm no expert, I warn you to take everything I say
with a few grains of salt and always check what I say before you use
it in an important research context. \textit{Caveat emptor}!

However, the hope is to give you a taste of what computational
optimization methods are all about, and introduce you to some of the important
terms in the field should you run into them later on. If/when you need to dive
into optimization techniques, hopefully these notes will give you an idea of 
where to jump off.

Code examples/exercises will be in Python (Python 2.x). The SciPy package
has a module `scipy.optimization' that has many optimization tools. For further
exploration, or for actually using optimization methods in your work, 
this would be a good place to start looking.

\section*{What Is Computational Optimization?}
	Mathematical optimization seeks to find the `best' choice among
	a set of possibilities; in addition, we want to find this best
	value with a minimum of computational effort. 
	Think of these examples: finding the lowest point on a radar image
	of the seafloor; determining reaction constants that best describe
	observed reaction rates; or, ordering the cities visited during a trip
	so as to minimize the gas used.

	The set of choices is frequently referred
	to as the `search space'; much of the time (particularly, in this tutorial)
	the search space is simply some subset of Euclidean space.
	The way we define `best' is as the minimum of some function $f$,
	the `objective function'. The objective function is a mapping
	from the search space to the real numbers. Only discussing minima
	is perfectly general:\ if your problem actually
	wants you to find the maximum of some function (e.\ g.\ number of users
	of your website), that's the same as minimizing the negative of the function.

	One of the most common examples of optimization in scientific contexts
	is function fitting: you have some data and want to find a function that
	describes it. The search space in this case would be the parameter values
	that characterize the possible functions 
	(e.\ g.\ slope and y-intercept for linear functions), 
	and the objective function
	would be some measure of the distance of your data from
	the fitted-function's values.
	Least-squares fitting is the classic example of this type of problem.

	There are, however, many many types of questions that may be phrased as
	optimization problems, and there have thus developed many many methods
	for finding solutions to these types of problems. Here, I would like to give
	some examples of the ways the field of mathematical optimization can
	be divided. The point is that you should get some idea of where your particular 
	problem lies, because each domain probably has methods designed to work well
	within it, methods that probably don't work well in other domains.
	
	These categories are not mutually-exclusive (an optimization
	problem can be both linear and convex, for example) and are certainly
	not exhaustive. In each dichotomy,
	I've tried to name first the division that is, in general, `easier' to perform.

	You may want to skip the next subsections and go straight to the
	exercises below if strapped for time. You can come back here if you need to.

  \subsection*{Heuristic vs.\ Algorithmic}
		An algorithm is a method that, if followed fully and correctly,
		is known to obtain the best answer; a heuristic should give you
		a good-enough answer, but maybe not the best, and sometimes it
		may be a terrible answer.
		Unfortunately, sometimes a heuristic method is all that can be
		found for a particular problem.
		It's always important to know which methods
		are heuristic and which are algorithmic. If you're using an alleged algorithm,
		make sure you know for which types of problems the algorithm is in fact
		known to find the best answer; you may think you can assume
		the result is the best answer, but if you're giving it the wrong kind
		of problem you may be wrong.

  \subsection*{Local vs.\ Global}
		Related to the issue of algorithmic vs.\ heuristic is the difference 
		between a local optimum and a global one: 
		just like optima for the calculus of single-variable
		functions, a local optimum means no \emph{nearby} choices
		are better, but there may be better choices elsewhere in the search space.
		Methods that find local optima are frequently faster and easier to use;
		you just have to make sure the result you get is the true global
		optimum. A quick way to do this is to start a local optimizer in multiple
		regions of you search space. However, this is clearly tedious, so if you
		think there's a high likelihood of getting stuck in a false minimum,
		know your options (a stochastic method may be smart; see below).

  \subsection*{Linear vs.\ Non-linear}
		Much of the classic work on optimization focuses on optimizing
		linear functions of the search space: `linear programming' is
		what it's called. While many problems can in fact be described,
		or at least approximated, by linear functions, many cannot. However,
		if yours can be, the linear methods are probably faster, and maybe
		algorithmic.

  \subsection*{Convex vs.\ Non-convex}
		Convex is a property of functions that essentially boils down to 
		``There's only one minimum and you can't get trapped in false-minima''.
		As with linear problems, if yours is a convex problem, the methods
		available to you are refined and powerful.

  \subsection*{Continuous vs.\ Discrete (`Combinatorial')}
		Though we're focusing on problems in which the search space
		is continuous, there are many problems in which it's discrete
		(e.\ g.\ ``Which route between these cities takes the least
		amount of time?''). The methods for these two classes of 
		problem are, not surprisingly, quite different, so make sure you don't
		try to fit a square peg into a round hole. 

  \subsection*{Deterministic (`Gradient') vs.\ Stochastic}
		Many of the classic optimization methods are deterministic,
		meaning that if you start the same problem with the same initial
		conditions, you're going to get the same result with the same
		intermediate steps. Because these methods frequently rely
		on calculating gradients to find which direction to move
		for finding the minimum, they're frequently known as `gradient'
		methods. 

		However, deterministic methods can have issues with getting stuck
		in false minima. To combat this, you can use a stochastic method,
		which, in one way or another, uses random number generation to sample larger
		portions of your search space. In general, though, stochastic methods,
		with their random number generation requirements, are going to 
		be computationally-costly compared to traditional deterministic
		methods. Many commercial optimization packages actually use some
		combination of the two.

\section*{Example: Scattering Cross-Section Simulation}
	So far, this has been pretty general and vague; let's get down
	to brass tacks with a (contrived) example. 

	Let's say you work in a nuclear physics lab, scattering a beam
	of particles off a target to study some nuclear-astrophysics process.
	The beam apparatus is controlled by two parameters: the energy of
	the particles, and the projection of the particles' average spin direction along
	the beam direction (the `helicity'). 

	When designing the experiment, you want to use 
	the parameter values that give you the highest 
	cross-section, so you can observe the largest-possible
	number of events.

	Luckily, one of your collaborators has provided you with a program that simulates
	the collision and reports the scattering cross-section, given your two
	parameters as inputs. Let's call their simulation program `Scatter'.
	Unfortunately, we're going to assume 
	that this program is somewhat computationally-intensive,
	so you can't simply play around with it to find what appears
	to be best.

	What you need, then, is to find the \emph{optimal} energy and helicity
	that give you the highest cross-section. To do this, we're going to use
	the Nelder-Mead optimization method.

	\subsection*{Nelder-Mead or `Downhill Simplex' Method}
		The Nelder-Mead method is a fairly-simple, deterministic, heuristic method
		for finding optima in non-linear, not-necessarily-convex, continuous problems.
		However, it's known to have
		a problem with returning non-optimal results. For that reason,
		these days more sophisticated methods are usually used; for
		the purposes of illustration, though, it's fine.

		Python's scipy.optimize.fmin function uses this method.

		Quick run-down of method, including defining simplex.

		The method has a nice intuitive visualization, as in 
		\href{http://userpages.umbc.edu/~rostamia/nelder-mead.html}{this gif}
		of a two-dimensional example. The reason for the name
		`Downhill Simplex' is pretty clear from watching this.

	\subsection*{Give It a Try}
		Suggest starting simplex that finds minimum; then
		suggest one that gets stuck. They can then play
		with different starting simplices and/or object functions.

\section*{Taste of Stochasticity: Simulated Annealing}
  Heuristic, but now better at finding
  global optimum.

	Stochastic.

  Related to Monte Carlo (the Metropolis method).

  Suggest they play around with Python's scipy.optimize.anneal function.
  Also, suggest that they can write their own (not during tutorial,
  but not too hard for after...).

\end{document}
